{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:50:59.379776Z",
     "iopub.status.busy": "2023-08-25T03:50:59.379298Z",
     "iopub.status.idle": "2023-08-25T03:51:00.391042Z",
     "shell.execute_reply": "2023-08-25T03:51:00.389659Z",
     "shell.execute_reply.started": "2023-08-25T03:50:59.379722Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\niran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\niran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:00.394151Z",
     "iopub.status.busy": "2023-08-25T03:51:00.393695Z",
     "iopub.status.idle": "2023-08-25T03:51:00.503156Z",
     "shell.execute_reply": "2023-08-25T03:51:00.501741Z",
     "shell.execute_reply.started": "2023-08-25T03:51:00.394111Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/niran/Desktop/spam_normal_emails.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:00.505239Z",
     "iopub.status.busy": "2023-08-25T03:51:00.504786Z",
     "iopub.status.idle": "2023-08-25T03:51:00.521464Z",
     "shell.execute_reply": "2023-08-25T03:51:00.519825Z",
     "shell.execute_reply.started": "2023-08-25T03:51:00.505205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:00.525223Z",
     "iopub.status.busy": "2023-08-25T03:51:00.524778Z",
     "iopub.status.idle": "2023-08-25T03:51:00.535999Z",
     "shell.execute_reply": "2023-08-25T03:51:00.534082Z",
     "shell.execute_reply.started": "2023-08-25T03:51:00.525188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into features (X) and labels (y)\n",
    "X = data['text']\n",
    "y = data['spam']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:00.538239Z",
     "iopub.status.busy": "2023-08-25T03:51:00.537774Z",
     "iopub.status.idle": "2023-08-25T03:51:29.325968Z",
     "shell.execute_reply": "2023-08-25T03:51:29.324723Z",
     "shell.execute_reply.started": "2023-08-25T03:51:00.538200Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "X_train_preprocessed = X_train.apply(preprocess_text)\n",
    "X_test_preprocessed = X_test.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:29.328164Z",
     "iopub.status.busy": "2023-08-25T03:51:29.327665Z",
     "iopub.status.idle": "2023-08-25T03:51:30.456404Z",
     "shell.execute_reply": "2023-08-25T03:51:30.455025Z",
     "shell.execute_reply.started": "2023-08-25T03:51:29.328118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a CountVectorizer to convert text data into numerical features\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_preprocessed)\n",
    "X_test_vectorized = vectorizer.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:30.458282Z",
     "iopub.status.busy": "2023-08-25T03:51:30.457918Z",
     "iopub.status.idle": "2023-08-25T03:51:30.466020Z",
     "shell.execute_reply": "2023-08-25T03:51:30.464773Z",
     "shell.execute_reply.started": "2023-08-25T03:51:30.458251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4582, 30326), (1146, 30326))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.shape,X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:30.467996Z",
     "iopub.status.busy": "2023-08-25T03:51:30.467608Z",
     "iopub.status.idle": "2023-08-25T03:51:30.512318Z",
     "shell.execute_reply": "2023-08-25T03:51:30.511009Z",
     "shell.execute_reply.started": "2023-08-25T03:51:30.467962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: akhave, Frequency: 1\n",
      "Word: allen, Frequency: 1\n",
      "Word: ann, Frequency: 1\n",
      "Word: approved, Frequency: 4\n",
      "Word: billie, Frequency: 1\n",
      "Word: bradley, Frequency: 1\n",
      "Word: carmen, Frequency: 1\n",
      "Word: carol, Frequency: 1\n",
      "Word: cc, Frequency: 2\n",
      "Word: chavira, Frequency: 1\n",
      "Word: click, Frequency: 1\n",
      "Word: coats, Frequency: 1\n",
      "Word: company, Frequency: 1\n",
      "Word: corp, Frequency: 1\n",
      "Word: document, Frequency: 1\n",
      "Word: ect, Frequency: 26\n",
      "Word: ely, Frequency: 1\n",
      "Word: enron, Frequency: 1\n",
      "Word: epsc, Frequency: 3\n",
      "Word: following, Frequency: 1\n",
      "Word: form, Frequency: 1\n",
      "Word: galvan, Frequency: 1\n",
      "Word: gary, Frequency: 1\n",
      "Word: hargrave, Frequency: 1\n",
      "Word: holloway, Frequency: 3\n",
      "Word: hou, Frequency: 13\n",
      "Word: indicated, Frequency: 1\n",
      "Word: information, Frequency: 1\n",
      "Word: jeff, Frequency: 1\n",
      "Word: jo, Frequency: 1\n",
      "Word: joann, Frequency: 3\n",
      "Word: kaminski, Frequency: 2\n",
      "Word: kinneman, Frequency: 1\n",
      "Word: link, Frequency: 1\n",
      "Word: louis, Frequency: 1\n",
      "Word: mccumber, Frequency: 1\n",
      "Word: michael, Frequency: 1\n",
      "Word: michelle, Frequency: 1\n",
      "Word: number, Frequency: 2\n",
      "Word: payroll, Frequency: 4\n",
      "Word: pm, Frequency: 2\n",
      "Word: property, Frequency: 1\n",
      "Word: received, Frequency: 1\n",
      "Word: reclass, Frequency: 1\n",
      "Word: reclassification, Frequency: 4\n",
      "Word: request, Frequency: 4\n",
      "Word: services, Frequency: 1\n",
      "Word: sorry, Frequency: 1\n",
      "Word: stella, Frequency: 1\n",
      "Word: stephen, Frequency: 1\n",
      "Word: stewart, Frequency: 1\n",
      "Word: subject, Frequency: 3\n",
      "Word: view, Frequency: 1\n",
      "Word: vince, Frequency: 4\n",
      "Word: wolfe, Frequency: 1\n",
      "Word: yes, Frequency: 1\n"
     ]
    }
   ],
   "source": [
    "sample_vectorized = X_train_vectorized[0]\n",
    "sample_vectorized_array = sample_vectorized.toarray()\n",
    "non_zero_indices = np.nonzero(sample_vectorized_array)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Displaying non-zero indices and corresponding word frequencies\n",
    "for word_index, frequency in zip(non_zero_indices[1], sample_vectorized_array[non_zero_indices]):\n",
    "    word = feature_names[word_index]\n",
    "    print(f\"Word: {word}, Frequency: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:30.514641Z",
     "iopub.status.busy": "2023-08-25T03:51:30.514131Z",
     "iopub.status.idle": "2023-08-25T03:51:30.530755Z",
     "shell.execute_reply": "2023-08-25T03:51:30.529496Z",
     "shell.execute_reply.started": "2023-08-25T03:51:30.514599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing and training the Naive Bayes classifier\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = nb_clf.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T03:51:30.534330Z",
     "iopub.status.busy": "2023-08-25T03:51:30.533976Z",
     "iopub.status.idle": "2023-08-25T03:51:30.553718Z",
     "shell.execute_reply": "2023-08-25T03:51:30.552241Z",
     "shell.execute_reply.started": "2023-08-25T03:51:30.534301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9895287958115183\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       856\n",
      "           1       0.98      0.98      0.98       290\n",
      "\n",
      "    accuracy                           0.99      1146\n",
      "   macro avg       0.99      0.99      0.99      1146\n",
      "weighted avg       0.99      0.99      0.99      1146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy and generating classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "\n",
    "The Naive Bayes classifier performed very well in this scenario, achieving high accuracy and balanced precision and recall for both spam and ham classes. The results suggest that the classifier is effective at distinguishing between spam and non-spam emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** The classifier is about 98.95% accurate in predicting whether an email is spam or not.\n",
    "\n",
    "**Precision:** About 98% of the predicted spam emails were actually spam, and about 99% of the predicted non-spam (ham) emails were actually non-spam.\n",
    "\n",
    "**Recall or Sensitivity:** The classifier identified about 98% of the actual spam emails and about 99% of the actual non-spam emails.\n",
    "\n",
    "**F1-Score:** The balanced measure of precision and recall is around 0.98 for spam and 0.99 for non-spam emails.\n",
    "\n",
    "**Support:** The test set included 856 non-spam (ham) emails and 290 spam emails.\n",
    "\n",
    "**Macro Avg:** The average performance across both classes (spam and ham) is around 0.99.\n",
    "\n",
    "**Weighted Avg:** Considering class distribution, the weighted average performance is around 0.99."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
